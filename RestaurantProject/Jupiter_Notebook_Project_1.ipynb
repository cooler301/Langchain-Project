{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f63625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a3829c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mamma Mia's Italian Kitchen\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature = 0.6)\n",
    "name = llm(\"I want to open a restaurant for Italian food.suggest a fency name for this \")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62b96369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Italian food.suggest a fency name for this'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables  = ['cuisine'],\n",
    "    template  = \"I want to open a restaurant for {cuisine} food.suggest a fency name for this\"\n",
    " )\n",
    "\n",
    "prompt_template_name.format(cuisine = \"Italian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f368c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nCasa Caliente'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "chain.run(\"Mexican \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff4c59c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables  = ['cuisine'],\n",
    "    template  = \"I want to open a restaurant for {cuisine} food.suggest a fency name for this\"\n",
    " )\n",
    "\n",
    "name_chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables  = ['restaurant_name'],\n",
    "    template  = \"Suggests some menu items for {restaurant_name} .Return it as a comma seperate\"\n",
    " )\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm,prompt=prompt_template_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7246d556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " list\n",
      "\n",
      "Butter Chicken, Korma, Tikka Masala, Rogan Josh, Saag Paneer, Biryani, Naan Bread, Samosas, Onion Bhaji.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains =[name_chain , food_items_chain])\n",
    "response=chain.run(\"Indian\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55f5aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables  = ['cuisine'],\n",
    "    template  = \"I want to open a restaurant for {cuisine} food.suggest a fency name for this\"\n",
    " )\n",
    "\n",
    "name_chain = LLMChain(llm=llm,prompt=prompt_template_name,output_key=\"restaurant_name\")\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables  = ['restaurant_name'],\n",
    "    template  = \"Suggests some menu items for {restaurant_name} \"\n",
    " )\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm,prompt=prompt_template_items,output_key=\"menu_items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b19a2748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabic',\n",
       " 'restaurant_name': '\\n\\nTaj Mahal Cuisine',\n",
       " 'menu_items': '\\n\\n-Tandoori Chicken\\n-Butter Chicken\\n-Matar Paneer\\n-Vegetable Biryani\\n-Palak Paneer\\n-Korma\\n-Saag\\n-Naan\\n-Samosa\\n-Papri Chaat\\n-Kulcha\\n-Kheer'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "   chains = [name_chain , food_items_chain],\n",
    "   input_variables  = ['cuisine'],\n",
    "   output_variables = ['restaurant_name','menu_items']\n",
    ")\n",
    "chain({'cuisine':'Arabic'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46b765ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elon Musk was born on June 28, 1971 and will be 52 years old in 2023.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install wikipedia\n",
    "from langchain.agents import AgentType,initialize_agent,load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "tools = load_tools([\"wikipedia\",\"llm-math\"],llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "           tools,\n",
    "           llm,\n",
    "           agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    ")\n",
    "\n",
    "agent.run(\"When was elon musk born?what its age in 2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa93e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['SERPAPI_API_KEY'] = '9b7d277a6f6812cc5c70bae2cfe290732e85fdcaae3ee376c1388db45a889b0b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46753785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\nuzzu\\anaconda3\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nuzzu\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nuzzu\\anaconda3\\lib\\site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nuzzu\\anaconda3\\lib\\site-packages (from requests->google-search-results) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nuzzu\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2023.11.17)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py): started\n",
      "  Building wheel for google-search-results (setup.py): finished with status 'done'\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32077 sha256=36882e44b5a53ee8a17167f2c7badf4a57f91e6b65ec3c78cee46a1696a29fea\n",
      "  Stored in directory: c:\\users\\nuzzu\\appdata\\local\\pip\\cache\\wheels\\6e\\42\\3e\\aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c97941f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The GDP of the US in 2022 is $25,462,700,000,000.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature = 0.6)\n",
    "\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "           tools,\n",
    "           llm,\n",
    "           agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    ")\n",
    "\n",
    "agent.run(\"What was the gdp of Us in 2022 ?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c2aa356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Curry Palace\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "name = chain.run(\"Indian\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e4b16b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Taco Loco\n"
     ]
    }
   ],
   "source": [
    "name = chain.run(\"Mexican\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d91ff037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05c7c8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Maharajah's Kitchen\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory()\n",
    "chain = LLMChain(llm=llm,prompt=prompt_template_name,memory=memory)\n",
    "name = chain.run(\"Indian\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2d4e3e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " restaurant\n",
      "\n",
      "Taco Fiesta\n"
     ]
    }
   ],
   "source": [
    "name = chain.run(\"Mexican\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "75e5ebd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Indian\n",
      "AI: \n",
      "\n",
      "Maharajah's Kitchen\n",
      "Human: Mexican\n",
      "AI:  restaurant\n",
      "\n",
      "Taco Fiesta\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02c41f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "661edbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 5 plus 5 is 10.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what is 5 plus 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d95e1780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first Cricket World Cup was won by the West Indies in 1975.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who won first world cricket world cup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8dff890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The captain of the winning team in the first Cricket World Cup was Clive Lloyd.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who was the captain of the winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44718d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first ever Cricket World Cup was held in 1975 and was won by the West Indies.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory  = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "convo = ConversationChain(llm=OpenAI(temperature=0.76),memory=memory)\n",
    "convo.run(\"Who won first world cricket world cup\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd61236d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The answer is 10.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what is 5 plus 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8115425f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm not sure. Who was the captain of the winning team?\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who was the captain of the winning team?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2826673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
